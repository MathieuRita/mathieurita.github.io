<!DOCTYPE html>
<html lang="en">

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Mathieu  Rita


</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>‚úíÔ∏è</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="https://mathieurita.github.io/">


<!-- Dark Mode -->
<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
        <!-- Social Icons -->
        <div class="navbar-brand social">
          <!--<a href="mailto:%6D%61%74%68%69%65%75.%72%69%74%61@%69%6E%72%69%61.%66%72" title="email"><i class="fas fa-envelope"></i></a>-->

<a href="https://scholar.google.com/citations?user=4VwTolgAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/MathieuRita" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/mathieu-rita-073b34134" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>
<a href="https://twitter.com/Mathieu_Rita" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a>













        </div>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
              
            </a>
          </li>
          
          <!-- Blog -->
          <!--
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          -->
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                Projects
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Publications
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
      <span class="font-weight-bold">Mathieu</span>  Rita
    </h1>
     <p class="desc"><a href="https://www.microsoft.com/en-us/research/collaboration/inria-joint-centre/" target="_blank" rel="noopener noreferrer">Inria-Microsoft Research Joint Lab</a>, <a href="https://cognitive-ml.fr/" target="_blank" rel="noopener noreferrer">Ecole Normale Sup√©rieure.</a></p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <picture>
    
    <source media="(max-width: 480px)" srcset="/assets/resized/profile_pic-480x480.jpeg">
    
    <img class="img-fluid z-depth-1 rounded" src="/assets/img/profile_pic.jpeg" alt="profile_pic.jpeg">
</source></picture>

      
      
        <div class="address">
          <p> Centre Sciences des Donn√©es (CSD) </p> <p>45 rue d'Ulm</p> <p>75005, Paris, France</p>
        </div>
      
    </div>
    

    <div class="clearfix">
      <p>I am a Ph.D. student under the supervision of Emmanuel Dupoux (ENS/FAIR), Olivier Pietquin (Google Brain) and Florian Strub (DeepMind). I work between the <a href="https://www.microsoft.com/en-us/research/collaboration/inria-joint-centre/" target="_blank" rel="noopener noreferrer">Inria-Microsoft Research Joint Lab</a> and the <a href="https://cognitive-ml.fr/" target="_blank" rel="noopener noreferrer">CoML</a> team in Paris, which is located at ENS Paris.</p>

<p>Prior to that, I received an engineering degree from Ecole Polytechnique and a MSc degree in Mathematics, Computer Vision and Machine Learning from Ecole Normale Sup√©rieure Paris-Saclay.</p>

<p><em>My research explores the theoretical and experimental aspects of training RL objectives with language models, with a specific focus on constructing self-play multi-agent systems. I particularly investigate how scaling populations and generations of agents can help address language learning challenges, such as overfitting, exploration or drift.¬†As an application, I simulate language evolution and study the pre-requisites necessary to the emergence of language universals, such as compositionality.</em></p>

    </div>

    
      <div class="news">
  <h2>News</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Jan 22, 2023</th>
          <td>
            
              <strong>[üìù PAPER]</strong> Our paper <a href="https://openreview.net/pdf?id=n-UHRIdPju" target="_blank" rel="noopener noreferrer"><em>Revisiting Populations in Multi-Agent Communication</em></a> has been accepted at ICLR‚Äô23.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Sep 14, 2022</th>
          <td>
            
              <strong>[üìù PAPER]</strong> Our paper <a href="https://arxiv.org/pdf/2209.15342.pdf" target="_blank" rel="noopener noreferrer"><em>Emergent Communication: Generalization and Overfitting in Lewis Games</em> has been accepted at NeurIPS‚Äô22.</a>

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jul 3, 2022</th>
          <td>
            
              <strong>[üáØüáµ WORKSHOP]</strong> Our Workshop <a href="https://ml4evolang.github.io/" target="_blank" rel="noopener noreferrer">‚ÄúMachine Learning and the Evolution of Language‚Äù</a> will take place at JCoLE‚Äô22 on September, 5th. 
Find all information on our <a href="https://ml4evolang.github.io/" target="_blank" rel="noopener noreferrer">webpage</a>.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Apr 29, 2022</th>
          <td>
            
              <strong>[üíª WORKSHOP]</strong> Our Workshop <a href="https://sites.google.com/view/emecom2022/home?authuser=0" target="_blank" rel="noopener noreferrer">‚ÄòEmergent communication: New frontiers‚Äô</a> takes place at ICLR‚Äô22 today

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Apr 22, 2022</th>
          <td>
            
              <strong>[üìù PAPER]</strong> Our paper <a href="https://arxiv.org/pdf/2204.12982.pdf" target="_blank" rel="noopener noreferrer"><em>On the Role of Population Heterogeneity in Emergent Communication</em></a> is presented at ICLR‚Äô22 this week.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Feb 1, 2021</th>
          <td>
            
              <strong>[‚úíÔ∏è PhD]</strong> I am starting a PhD on <em>Emergent Communication</em> under the supervision of Emmanuel Dupoux, Olivier Pietquin &amp; Florian Strub.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jan 15, 2021</th>
          <td>
            
              <strong>[üë®‚Äçüé® ART]</strong> Our generated video <a href="https://computervisionart.com/pieces2021/dreamy-cops/" target="_blank" rel="noopener noreferrer"><em>Dreamy Cops</em></a> is exposed in the online CVPR <a href="https://computervisionart.com/pieces2021" target="_blank" rel="noopener noreferrer">Computer Vision Art Gallery</a>.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Nov 20, 2020</th>
          <td>
            
              <strong>[üìù PAPER]</strong> Our paper <a href="https://arxiv.org/pdf/2010.01878.pdf" target="_blank" rel="noopener noreferrer"><em>‚ÄúLazImpa‚Äù: Lazy and Impatient neural agents learn to communicate efficiently</em></a> is presented to CoNLL‚Äô20.

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>Selected publications</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="michelrevisiting" class="col-sm-8">
    
      <div class="title">Revisiting Populations in Multi-Agent Communication</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  Michel, Paul,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Rita, Mathieu</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Mathewson, Kory Wallace,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tieleman, Olivier,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Lazaridou, Angeliki
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>The 11th International Conference on Learning Representations (ICLR) 2023</em>
      
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://openreview.net/pdf?id=n-UHRIdPju" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Despite evidence from cognitive sciences that larger groups of speakers tend to develop more structured languages in human communication, scaling up to populations has failed to yield significant benefits in emergent multi-agent communication. In this paper we advocate for an alternate population-level training paradigm for referential games based on the idea of "partitioning" the agents into sender-receiver pairs and limiting co-adaptation across pairs. We show that this results in optimizing a different objective at the population level, where agents maximize (1) their respective "internal" communication accuracy and (2) some measure of alignment between agents. In experiments, we find that this leads to the emergence of languages that are significantly more compositional. Moreover, when agents are trained in populations that are not fully connected (ie. not all agent pairs interact at training time), this approach reduces multi-linguality and improves zero-shot communication with new agents (ie. agents are able to communicate successfully with other agents outside their training partners).</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="rita2022neurips" class="col-sm-8">
    
      <div class="title">Emergent Communication: Generalization and Overfitting in Lewis Games</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Rita, Mathieu</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  Tallec, Corentin,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  Michel, Paul,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  Grill, Jean-Bastien,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  Pietquin, Olivier,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  Dupoux, Emmanuel,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Strub, Florian
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>36th Conference on Neural Information Processing Systems (NeurIPS)</em>
      
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2209.15342.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Lewis signaling games are a class of simple communication games for simulating the emergence of language. In these games, two agents must agree on a communication protocol in order to solve a cooperative task. Previous work has shown that agents trained to play this game with reinforcement learning tend to develop languages that display undesirable properties from a linguistic point of view (lack of generalization, lack of compositionality, etc). In this paper, we aim to provide better understanding of this phenomenon by analytically studying the learning problem in Lewis games. As a core contribution, we demonstrate that the standard objective in Lewis games can be decomposed in two components: a co-adaptation loss and an information loss. This decomposition enables us to surface two potential sources of overfitting, which we show may undermine the emergence of a structured communication protocol. In particular, when we control for overfitting on the co-adaptation loss, we recover desired properties in the emergent languages: they are more compositional and generalize better</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="rita2022role" class="col-sm-8">
    
      <div class="title">On the role of population heterogeneity in emergent communication</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Rita, Mathieu</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Strub, Florian,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  Grill, Jean-Bastien,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  Pietquin, Olivier,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and Dupoux, Emmanuel
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>The Tenth International Conference on Learning Representations (ICLR)</em>
      
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2204.12982.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
      <a href="https://twitter.com/Mathieu_Rita/status/1521132871313932288" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Blog</a>
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Populations have often been perceived as a structuring component for language to emerge and evolve: the larger the population, the more structured the language. While this observation is widespread in the sociolinguistic literature, it has not been consistently reproduced in computer simulations with neural agents. In this paper, we thus aim to clarify this apparent contradiction. We explore emergent language properties by varying agent population size in the speaker-listener Lewis Game. After reproducing the experimental difference, we challenge the simulation assumption that the agent community is homogeneous. We then investigate how speaker-listener asymmetry alters language structure through the analysis a potential diversity factor: learning speed. From then, we leverage this observation to control population heterogeneity without introducing confounding factors. We finally show that introducing such training speed heterogeneities naturally sort out the initial contradiction: larger simulated communities start developing more stable and structured languages.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="rita2020lazimpa" class="col-sm-8">
    
      <div class="title">" LazImpa": Lazy and Impatient neural agents learn to communicate efficiently</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Rita, Mathieu</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Chaabouni, Rahma,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and Dupoux, Emmanuel
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of CoNLL</em>
      
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2010.01878.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Previous work has shown that artificial neural agents naturally develop surprisingly non-efficient codes. This is illustrated by the fact that in a referential game involving a speaker and a listener neural networks optimizing accurate transmission over a discrete channel, the emergent messages fail to achieve an optimal length. Furthermore, frequent messages tend to be longer than infrequent ones, a pattern contrary to the Zipf Law of Abbreviation (ZLA) observed in all natural languages. Here, we show that near-optimal and ZLA-compatible messages can emerge, but only if both the speaker and the listener are modified. We hence introduce a new communication system, ‚ÄúLazImpa‚Äù, where the speaker is made increasingly lazy, i.e., avoids long messages, and the listener impatient, i.e., seeks to guess the intended content as soon as possible.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>
</div>

    

    
    <div class="social">
      <div class="contact-icons">
        <a href="mailto:%6D%61%74%68%69%65%75.%72%69%74%61@%69%6E%72%69%61.%66%72" title="email"><i class="fas fa-envelope"></i></a>

<a href="https://scholar.google.com/citations?user=4VwTolgAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/MathieuRita" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/mathieu-rita-073b34134" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>
<a href="https://twitter.com/Mathieu_Rita" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a>













      </div>
      <div class="contact-note"></div>
    </div>
    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    ¬© Copyright 2023 Mathieu  Rita.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

    
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  





</html>
