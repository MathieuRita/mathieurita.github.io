---
---

@article{michelrevisiting,
  title={Revisiting Populations in Multi-Agent Communication},
  author={Michel, Paul and Rita, Mathieu and Mathewson, Kory Wallace and Tieleman, Olivier and Lazaridou, Angeliki},
  year={2023},
  journal={The 11th International Conference on Learning Representations (ICLR) 2023},
  selected = {true},
  pdf = {https://openreview.net/pdf?id=n-UHRIdPju},
  abstract = {Despite evidence from cognitive sciences that larger groups of speakers tend to develop more structured languages in human communication, scaling up to populations has failed to yield significant benefits in emergent multi-agent communication. In this paper we advocate for an alternate population-level training paradigm for referential games based on the idea of "partitioning" the agents into sender-receiver pairs and limiting co-adaptation across pairs. We show that this results in optimizing a different objective at the population level, where agents maximize (1) their respective "internal" communication accuracy and (2) some measure of alignment between agents. In experiments, we find that this leads to the emergence of languages that are significantly more compositional. Moreover, when agents are trained in populations that are not fully connected (ie. not all agent pairs interact at training time), this approach reduces multi-linguality and improves zero-shot communication with new agents (ie. agents are able to communicate successfully with other agents outside their training partners).},
}}

@article{gundem2022clonal,
  title={Clonal evolution during metastatic spread in high-risk neuroblastoma},
  author={Gundem, Gunes and Levine, Max F and Roberts, Stephen S and Cheung, Irene Y and Medina-Matrinez, Juan S and Feng, Yi and Arango-Ossa, Juan E and Chadoutaud, Loic and Rita, Mathieu and Asimomitis, Georgios and others},
  journal={bioRxiv},
  pages={2022--08},
  year={2022},
  publisher={Cold Spring Harbor Laboratory},
  pdf = {https://www.biorxiv.org/content/biorxiv/early/2022/08/15/2022.08.15.503973.full.pdf},
  abstract = {High-risk neuroblastoma is generally metastatic and often lethal. Using genomic profiling of 470 sequential and spatially separated samples from 283 patients, we characterize subtype-specific genetic evolutionary trajectories from diagnosis, through progression and end-stage metastatic disease. Clonal tracing timed disease initiation to embryogenesis. Continuous acquisition of structural variants at disease defining loci (MYCN, TERT, MDM2-CDK4) followed by convergent evolution of mutations targeting shared pathways emerged as the predominant feature of progression. At diagnosis metastatic clones were already established at distant sites where they could stay dormant, only to cause relapses years later and spread via metastasis-to-metastasis and polyclonal seeding after therapy.},
  selected = {false},
}}

@article{rita2022neurips,
  title={Emergent Communication: Generalization and Overfitting in Lewis Games},
  author={Rita, Mathieu and Tallec, Corentin and Michel, Paul and Grill, Jean-Bastien and Pietquin, Olivier and Dupoux, Emmanuel and Strub, Florian},
  journal={36th Conference on Neural Information Processing Systems (NeurIPS)},
  year={2022},
  selected    = {true},
  pdf = {https://arxiv.org/pdf/2209.15342.pdf},
  abstract = {Lewis signaling games are a class of simple communication games for simulating the emergence of language. In these games, two agents must agree on a communication protocol in order to solve a cooperative task. Previous work has shown that agents trained to play this game with reinforcement learning tend to develop languages that display undesirable properties from a linguistic point of view (lack of generalization, lack of compositionality, etc). In this paper, we aim to provide better understanding of this phenomenon by analytically studying the learning problem in Lewis games. As a core contribution, we demonstrate that the standard objective in Lewis games can be decomposed in two components: a co-adaptation loss and an information loss. This decomposition enables us to surface two potential sources of overfitting, which we show may undermine the emergence of a structured communication protocol. In particular, when we control for overfitting on the co-adaptation loss, we recover desired properties in the emergent languages: they are more compositional and generalize better},
}}

@article{rita2022role,
  title={On the role of population heterogeneity in emergent communication},
  author={Rita, Mathieu and Strub, Florian and Grill, Jean-Bastien and Pietquin, Olivier and Dupoux, Emmanuel},
  journal={The Tenth International Conference on Learning Representations (ICLR)},
  year={2022},
  selected    = {true},
  abstract = {Populations have often been perceived as a structuring component for language to emerge and evolve: the larger the population, the more structured the language. While this observation is widespread in the sociolinguistic literature, it has not been consistently reproduced in computer simulations with neural agents. In this paper, we thus aim to clarify this apparent contradiction. We explore emergent language properties by varying agent population size in the speaker-listener Lewis Game. After reproducing the experimental difference, we challenge the simulation assumption that the agent community is homogeneous. We then investigate how speaker-listener asymmetry alters language structure through the analysis a potential diversity factor: learning speed. From then, we leverage this observation to control population heterogeneity without introducing confounding factors. We finally show that introducing such training speed heterogeneities naturally sort out the initial contradiction: larger simulated communities start developing more stable and structured languages.},
  pdf = {https://arxiv.org/pdf/2204.12982.pdf},
  blog = {https://twitter.com/Mathieu_Rita/status/1521132871313932288}
}}

@article{rita2020lazimpa,
  title={" LazImpa": Lazy and Impatient neural agents learn to communicate efficiently},
  author={Rita, Mathieu and Chaabouni, Rahma and Dupoux, Emmanuel},
  journal={In Proceedings of CoNLL},
  year={2020},
  selected    = {true},
  abstract = {Previous work has shown that artificial neural agents naturally develop surprisingly non-efficient codes. This is illustrated by the fact that in a referential game involving a speaker and a listener neural networks optimizing accurate transmission over a discrete channel, the emergent messages fail to achieve an optimal length. Furthermore, frequent messages tend to be longer than infrequent ones, a pattern contrary to the Zipf Law of Abbreviation (ZLA) observed in all natural languages. Here, we show that near-optimal and ZLA-compatible messages can emerge, but only if both the speaker and the listener are modified. We hence introduce a new communication system, “LazImpa”, where the speaker is made increasingly lazy, i.e., avoids long messages, and the listener impatient, i.e., seeks to guess the intended content as soon as possible.},
  pdf = {https://arxiv.org/pdf/2010.01878.pdf}
}



@string{aps = {American Physical Society,}}
